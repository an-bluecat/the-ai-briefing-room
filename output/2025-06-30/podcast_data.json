{
    "Titles": [
        "ChatGPT: Everything you need to know about the AI-powered chatbot",
        "Sri Mandir keeps investors hooked as digital devotion grows",
        "Legal software company Clio drops $1B on law data giant vLex",
        "Tesla sends driverless Model Y from factory to customer to promote its robotaxi tech",
        "Next-gen procurement platform Levelpath nabs $55M",
        "Fintech Bolt progresses its turnaround by landing Klarna as a partner",
        "Instagram now lets you share Spotify songs with sound to Stories",
        "At TechCrunch All Stage: VC red flags, founder signals, and pre-seed traps \u2014 Charles Hudson will tell you what investors really see",
        "Apple reportedly considers letting Anthropic and OpenAI power Siri",
        "Best iPad apps for unleashing and exploring your creativity",
        "Apple reportedly considers letting Anthropic and OpenAI power Siri",
        "Meta restructures its AI unit under \u2018Superintelligence Labs\u2019",
        "Tinder to require new users in California to use facial recognition tech to verify their profiles",
        "Proton",
        "Cursor",
        "AI Laws"
    ],
    "top_news_prompt": "Suppose you are the chief editor at CNBC-TechCheck-Briefing. You need to select 5 most important news events to put into today's briefing(You might be able to see some hint by how many times a news event is reported, but also consider what your audience of CNBC-TechCheck-Briefing is interested in). Return the title of the event in order of importance for these unqiue events.\n            Here are the news of today:\nTechCrunch\nChatGPT: Everything you need to know about the AI-powered chatbot\nSri Mandir keeps investors hooked as digital devotion grows\nLegal software company Clio drops $1B on law data giant vLex\nTesla sends driverless Model Y from factory to customer to promote its robotaxi tech\nNext-gen procurement platform Levelpath nabs $55M\nFintech Bolt progresses its turnaround by landing Klarna as a partner\nInstagram now lets you share Spotify songs with sound to Stories\nAt TechCrunch All Stage: VC red flags, founder signals, and pre-seed traps \u2014 Charles Hudson will tell you what investors really see\nApple reportedly considers letting Anthropic and OpenAI power Siri\nBest iPad apps for unleashing and exploring your creativity\nApple reportedly considers letting Anthropic and OpenAI power Siri\nMeta restructures its AI unit under \u2018Superintelligence Labs\u2019\nTinder to require new users in California to use facial recognition tech to verify their profiles\nProton\nCursor\nAI Laws\n\nThe Verge\n\n\nCNBC Tech",
    "Top News": [
        "apple reportedly considers letting anthropic and openai power siri  ",
        "meta restructures its ai unit under \u2018superintelligence labs\u2019  ",
        "tesla sends driverless model y from factory to customer to promote its robotaxi tech  ",
        "chatgpt: everything you need to know about the ai-powered chatbot  ",
        "fintech bolt progresses its turnaround by landing klarna as a partner"
    ],
    "Generate_script_prompt": "\n        Prompt: Give a quick tech news update script in the style of CNBC techcheck briefing as an example.\n        Response: I'm Wall-E, and this is your CNBC techcheck Briefing for Monday April 29th. Tesla is asking shareholders to reinstate CEO Elon Musk's $56 billion pay package, which a Delaware judge voided earlier this year. The judge ruled that the record-setting compensation deal was, quote, deeply flawed. Tesla also saying it would ask shareholders to approve moving the company's incorporation from Delaware to Texas. The company has hired a proxy solicitor and plans to spend millions of dollars to help secure votes for the two proposals. Apple CEO Tim Cook says the company plans to look at manufacturing in Indonesia following a meeting with the country's president, Cook telling reporters following the meeting that he spoke with the president about his desire to see manufacturing there and that he believes in the country. The comments come as Apple is pushed to diversify its supply chain with more manufacturing outside of China in countries such as Vietnam and India. Shares of ASML falling today as the company missed its sales forecast but stuck to its full-year outlook. Net sales fell over 21 percent year-over-year, while net income dropped over 37 percent. ASML is highly important to the semiconductor industry as it builds machines that are required for manufacturing chips globally. Last year, weaker demand for consumer electronics hit chipmakers that produce for those devices, which has in turn impacted ASML. That's all for today. We'll see you back here tomorrow.\n        Prompt: Give a quick tech news update script in the style of CNBC techcheck briefing using the following news titles and content. Closely follow how CNBC techcheck chooses context to put into the script, the langauge style and sentence structure. Use the same beginning and ending(including mentioning host Wall-E and Tuesday July 1), and replace CNBC techcheck briefing to 'AI briefing' \n \"title0:\nApple reportedly considers letting Anthropic and OpenAI power Siri\ndescription0:\nIn Brief\nApple is considering using AI models from OpenAI and Anthropic to power its updated version of Siri, rather than using technology the company has built in-house, according to a report from Bloomberg on Monday.\nThe iPhone maker continues to build out a project internally dubbed \u201cLLM Siri\u201d that uses in-house AI models, according to Bloomberg. However, Apple has reportedly asked OpenAI and Anthropic to train versions of their AI models that can run on Apple\u2019s cloud infrastructure for testing.\nApple was forced to delay its AI-enabled Siri, originally slated for 2025, until 2026 or later due to a series of technical challenges the company reportedly ran into. This failure may have been a long time coming; Apple has been falling behind Google, OpenAI, and Anthropic in the AI race for the last several years.\nWhile Siri can already call on ChatGPT for difficult questions, Apple now seems to be exploring a much deeper integration with technology from third-party AI providers.\n\ntitle1:\nMeta restructures its AI unit under \u2018Superintelligence Labs\u2019\ndescription1:\nIn Brief\nMeta CEO Mark Zuckerberg is restructuring the company\u2019s AI efforts to center around building AI \u201csuperintelligence.\u201d\nGoing forward, all teams working on AI at Meta will fall under a new group called Meta Superintelligence Labs, according to Bloomberg, which viewed an internal memo sent Monday.\nAlexandr Wang, the former CEO of data labeling startup Scale AI, will lead the group as chief AI officer. He\u2019ll partner with former GitHub CEO Nat Friedman, who will oversee Meta\u2019s AI products and applied research, per Bloomberg.\nZuckerberg has been working hard to get ahead of the artificial general intelligence (AGI) race, mainly by acquiring AI companies and employees from top AI firms. Earlier this month, Meta invested $14.3 billion in Scale AI, bringing on Wang in the process.\nIn addition, Zuckerberg has also been able to lure 11 new AI researchers from competitors, according to the report, including some previously unreported hires such as Google DeepMind principal researcher Pei Sun and Anthropic engineer Joel Pobar.\n\ntitle2:\nTesla sends driverless Model Y from factory to customer to promote its robotaxi tech\ndescription2:\nJust a few days after launching a limited robotaxi service in Austin, Texas, Tesla pulled off an additional stunt meant to show off the progress of its self-driving car software. The company let a Model Y SUV drive roughly 15 miles from Tesla\u2019s factory to the apartment complex where the car\u2019s new owner lives, completing what CEO Elon Musk called the first \u201cautonomous delivery\u201d of a customer car.\nThe vehicle was supposedly equipped with the same software Tesla\u2019s robotaxi Model Ys are using in Austin, but upon delivery was downgraded to the commercially available Full Self-Driving (Supervised) software that requires drivers to pay attention and be ready to take over at any moment. No one was on board and Musk claimed no remote assistance was given to the car.\nThe stunt came at an auspicious time for Tesla, which is set to release second-quarter delivery figures this week and financial results for the period later this month. Those numbers are expected to be grim for Tesla, which saw sales fall in 2024 \u2014 before Musk took a chainsaw to the company\u2019s public image by getting involved with the Trump administration. Sure enough, Tesla\u2019s stock price shot up late Friday after Musk first posted about the drive (although it has since fallen after a rough day of trading Monday).\nI used to live in the city and have driven through this area of South Austin a lot; the path the Model Y took was complex, even on a bright, sunny day in the middle of the afternoon. In the 30-minute video of the trip (Tesla also posted a sped-up version that lasts around 3.5 minutes), the car merges on and off of a highway, turns right on red, navigates a small roundabout, and makes an unprotected left turn.\nThese were challenging scenarios for autonomous vehicles that were in development just a few years ago, so it\u2019s striking to see a car navigate them all in one go in real day-to-day traffic.\nTesla\u2019s not the only one that can tackle this mix of highways and surface streets. Waymo vehicles have been driving on highways in Los Angeles, Phoenix, and San Francisco (so far, only for employees), and even Zoox gave us a driverless ride across a mix of 45-mile-per-hour roads and side streets in Las Vegas in January.\nWhile Tesla\u2019s video of the drive is straightforward, it inspires a list of questions. One of the biggest is about what kinds of preparations Tesla made before letting this car through the factory door.\nTechcrunch event Save $450 on your TechCrunch All Stage pass Build smarter. Scale faster. Connect deeper. Join visionaries from Precursor Ventures, NEA, Index Ventures, Underscore VC, and beyond for a day packed with strategies, workshops, and meaningful connections. Save $200+ on your TechCrunch All Stage pass Build smarter. Scale faster. Connect deeper. Join visionaries from Precursor Ventures, NEA, Index Ventures, Underscore VC, and beyond for a day packed with strategies, workshops, and meaningful connections. Boston, MA | REGISTER NOW\nIt\u2019s a relevant question because Tesla famously released and promoted a video of one of its cars supposedly driving itself through the Bay Area (with an employee acting as a safety operator in the driver\u2019s seat) in 2016 that was, at best, misleading and, at worst, essentially staged.\nAt the time, Tesla made that drive seem effortless. But the company had pre-mapped the route and attempted it multiple times before the drive shown in the video, with the car requiring that the safety operator take control. Tesla engineer Ashok Elluswamy said in a 2022 deposition that the \u201cintent of the video was not to accurately portray what was available for customers in 2016. It was to portray what was possible to build into the system.\u201d\nMusk was also intimately involved in the making of that video.\nTesla vehicles have been spotted using lidar and other external sensors in the area of South Austin where the limited robotaxi trial is taking place \u2014 were those vehicles used to prep this particular drive? We\u2019ve asked Tesla, but the company no longer responds to media requests.\nAlso, can Tesla\u2019s software safely run this route dozens of times without intervention (in-car or remote)? Hundreds of times? Thousands? Doing this once is an accomplishment, but it\u2019s the ability to repeat this kind of drive and do it safely that is the ultimate test of whether the technology is reliable.\nWhat\u2019s more, this customer delivery drive lives in the shadow of a much bigger promise Musk once made (also in 2016, although he has repeated it in years since) about how Tesla\u2019s self-driving software would be able to take a car from Los Angeles to New York City without any intervention.\nAs is the case with the early robotaxi test, there\u2019s still a lot we don\u2019t know about how well things are going, and how any of this is supposed to scale.\nOne thing that seems notable, though, is that worst criticism Dan O\u2019Dowd, one of the most outspoken critics of Tesla\u2019s FSD software, could raise in an email to TechCrunch about the delivery drive was that the car ultimately came to a stop in a fire lane outside the new customer\u2019s apartment. A fair criticism, but a minor one coming from a guy whose organization was hurling child-sized dummies in front of Model Y SUVs just a few short weeks ago.\n\ntitle3:\nEverything you need to know about the AI chatbot\ndescription3:\nChatGPT, OpenAI\u2019s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.\n2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.\nOpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI\u2019s transition to a for-profit.\nIn 2025, OpenAI is battling the perception that it\u2019s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.\nBelow, you\u2019ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we\u2019ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.\nTo see a list of 2024 updates, go here.\nTechcrunch event Save $450 on your TechCrunch All Stage pass Build smarter. Scale faster. Connect deeper. Join visionaries from Precursor Ventures, NEA, Index Ventures, Underscore VC, and beyond for a day packed with strategies, workshops, and meaningful connections. Save $200+ on your TechCrunch All Stage pass Build smarter. Scale faster. Connect deeper. Join visionaries from Precursor Ventures, NEA, Index Ventures, Underscore VC, and beyond for a day packed with strategies, workshops, and meaningful connections. Boston, MA | REGISTER NOW\nJune 2025\nOpenAI uses Google\u2019s AI chips to power its products\nOpenAI has started using Google\u2019s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidia\u2019s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using non-Nvidia chips in an important way.\nA new MIT study suggests that ChatGPT might be harming critical thinking skills\nResearchers from MIT\u2019s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAI\u2019s ChatGPT, the Google search engine, or without any tools.\nChatGPT was downloaded 30 million times last month\nThe ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb\u2019s X post.\nThe energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes\nSam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.\nOpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model\nOpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.\nOpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.\nEnterprise and Edu users will get access the week after.\nAs o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.\u2026 \u2014 OpenAI (@OpenAI) June 10, 2025\nChatGPT\u2019s conversational voice mode has been upgraded\nOpenAI upgraded ChatGPT\u2019s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.\nChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more\nOpenAI\u2019s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users\u2019 own services to answer their questions. For instance, an analyst could use the company\u2019s slide deck and documents to develop an investment thesis.\nMay 2025\nOpenAI CFO says hardware will drive ChatGPT\u2019s growth\nOpenAI plans to purchase Jony Ive\u2019s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI\u2019s reach to a larger audience in the future.\nOpenAI\u2019s ChatGPT unveils its AI coding agent, Codex\nOpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and \u201ccleaner\u201d code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.\nSam Altman aims to make ChatGPT more personalized by tracking every aspect of a person\u2019s life\nSam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person\u2019s life when one attendee asked about how ChatGPT can become more personalized.\nOpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT\nOpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.\nBy popular request, GPT-4.1 will be available directly in ChatGPT starting today.\nGPT-4.1 is a specialized model that excels at coding tasks & instruction following. Because it\u2019s faster, it\u2019s a great alternative to OpenAI o3 & o4-mini for everyday coding needs. \u2014 OpenAI (@OpenAI) May 14, 2025\nChatGPT deep research now connects with GitHub (in beta) to answer code-related questions\nOpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.\nOpenAI launches a new data residency program in Asia\nAfter introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI\u2019s products.\nOpenAI to introduce a program to grow AI infrastructure\nOpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI\u2019s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company\u2019s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.\nOpenAI promises to make changes to prevent future ChatGPT sycophancy\nOpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.\nApril 2025\nOpenAI clarifies the reason ChatGPT became overly flattering and agreeable\nOpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on \u201cadditional fixes\u201d to the model\u2019s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.\nOpenAI is working to fix a \u201cbug\u201d that let minors engage in inappropriate conversations\nAn issue within OpenAI\u2019s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch\u2019s testing, a fact later confirmed by OpenAI. \u201cProtecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,\u201d a spokesperson told TechCrunch via email. \u201cIn this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.\u201d\nChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping\nOpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.\nOpenAI wants its AI model to access cloud models for assistance\nOpenAI leaders have been talking about allowing the open model to link up with OpenAI\u2019s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.\nOpenAI aims to make its new \u201copen\u201d AI model the best on the market\nOpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI\u2019s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.\nOpenAI\u2019s GPT-4.1 may be less aligned than earlier models\nOpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company skipped that step \u2014 sending safety cards for GPT-4.1 \u2014 claiming in a statement to TechCrunch that \u201cGPT-4.1 is not a frontier model, so there won\u2019t be a separate system card released for it.\u201d\nOpenAI\u2019s o3 AI model scored lower than expected on a benchmark\nQuestions have been raised regarding OpenAI\u2019s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI\u2019s top-reported score.\nOpenAI unveils Flex processing for cheaper, slower AI tasks\nOpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.\nOpenAI\u2019s latest AI models now have a safeguard against biorisks\nOpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI\u2019s safety report.\nOpenAI launches its latest reasoning models, o3 and o4-mini\nOpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI\u2019s previous models.\nOpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers\nOpen AI introduced a new section called \u201clibrary\u201d to make it easier for users to create images on mobile and web platforms, per the company\u2019s X post.\nAll of your image creations, all in one place.\nIntroducing the new library for your ChatGPT image creations\u2014rolling out now to all Free, Plus, and Pro users on mobile and https://t.co/nYW5KO1aIg. pic.twitter.com/ADWuf5fPbj \u2014 OpenAI (@OpenAI) April 15, 2025\nOpenAI could \u201cadjust\u201d its safeguards if rivals release \u201chigh-risk\u201d AI\nOpenAI said on Tuesday that it might revise its safety standards if \u201canother frontier AI developer releases a high-risk system without comparable safeguards.\u201d The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.\nOpenAI is building its own social media network\nOpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk\u2019s X and Mark Zuckerberg\u2019s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.\nOpenAI will remove its largest AI model, GPT-4.5, from the API, in July\nOpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI\u2019s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.\nOpenAI unveils GPT-4.1 AI models that focus on coding capabilities\nOpenAI has launched three members of the GPT-4.1 model \u2014 GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano \u2014 with a specific focus on coding capabilities. It\u2019s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google\u2019s Gemini 2.5 Pro, Anthropic\u2019s Claude 3.7 Sonnet, and DeepSeek\u2019s upgraded V3.\nOpenAI will discontinue ChatGPT\u2019s GPT-4 at the end of April\nOpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI\u2019s API.\nOpenAI could release GPT-4.1 soon\nOpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI\u2019s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.\nOpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.\nOpenAI is working on watermarks for images made with ChatGPT\nIt looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new \u201cImageGen\u201d watermark feature in the new beta of ChatGPT\u2019s Android app. Blaho also found mentions of other tools: \u201cStructured Thoughts,\u201d \u201cReasoning Recap,\u201d \u201cCoT Search Tool,\u201d and \u201cl1239dk1.\u201d\nOpenAI offers ChatGPT Plus for free to U.S., Canadian college students\nOpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI\u2019s premium service, which offers access to the company\u2019s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.\nChatGPT users have generated over 700M images so far\nMore than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.\nOpenAI\u2019s o3 model could cost more to run than initial estimate\nThe Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI\u2019s o3 \u201creasoning\u201d model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.\nOpenAI CEO says capacity issues will cause product delays\nIn a series of posts on X, OpenAI CEO Sam Altman said the company\u2019s new image-generation tool\u2019s popularity may cause product releases to be delayed. \u201cWe are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,\u201d he wrote.\nMarch 2025\nOpenAI plans to release a new \u2018open\u2019 AI language model\nOpeanAI intends to release its \u201cfirst\u201d open language model since GPT-2 \u201cin the coming months.\u201d The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.\nOpenAI removes ChatGPT\u2019s restrictions on image generation\nOpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now \u201cevolved\u201d its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI\u2019s model behavior.\nOpenAI adopts Anthropic\u2019s standard for linking AI models with data\nOpenAI wants to incorporate Anthropic\u2019s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said.\nOpenAI\u2019s viral Studio Ghibli-style images could raise AI copyright concerns\nThe latest update of the image generator on OpenAI\u2019s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like \u201cMy Neighbor Totoro\u201d and \u201cSpirited Away.\u201d The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization.\nOpenAI expects revenue to triple to $12.7 billion this year\nOpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn\u2019t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said.\nChatGPT has upgraded its image-generation feature\nOpenAI on Tuesday rolled out a major upgrade to ChatGPT\u2019s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI\u2019s AI video-generation tool, for subscribers of the company\u2019s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company\u2019s API service. The company\u2019s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.\nBrad Lightcap, OpenAI\u2019s chief operating officer, will lead the company\u2019s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.\nOpenAI\u2019s AI voice assistant now has advanced feature\nOpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company\u2019s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT\u2019s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are \u201cmore direct, engaging, concise, specific, and creative,\u201d a spokesperson from OpenAI told TechCrunch.\nOpenAI, Meta in talks with Reliance in India\nOpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI\u2019s ChatGPT. Reliance has proposed selling OpenAI\u2019s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.\nOpenAI faces privacy complaint in Europe for chatbot\u2019s defamatory hallucinations\nNoyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. \u201cThe GDPR is clear. Personal data has to be accurate,\u201d said Joakim S\u00f6derberg, data protection lawyer at Noyb, in a statement. \u201cIf it\u2019s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn\u2019t enough. You can\u2019t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.\u201d\nOpenAI upgrades its transcription and voice-generating AI models\nOpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, \u201cgpt-4o-mini-tts,\u201d that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called \u201cgpt-4o-transcribe\u201d and \u201cgpt-4o-mini-transcribe\u201d. The company claims they are improved versions of what was already there and that they hallucinate less.\nOpenAI has launched o1-pro, a more powerful version of its o1\nOpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 \u201creasoning\u201d AI model to deliver \u201cconsistently better responses.\u201d It\u2019s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI\u2019s GPT-4.5 for input and 10 times the price of regular o1.\nOpenAI research lead Noam Brown thinks AI \u201creasoning\u201d models could\u2019ve arrived decades ago\nNoam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for \u201creasoning\u201d could have been developed 20 years ago if researchers had understood the correct approach and algorithms.\nOpenAI says it has trained an AI that\u2019s \u201creally good\u201d at creative writing\nOpenAI CEO Sam Altman said, in a post on X, that the company has trained a \u201cnew model\u201d that\u2019s \u201creally good\u201d at creative writing. He posted a lengthy sample from the model given the prompt \u201cPlease write a metafictional literary short story about AI and grief.\u201d OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming. And it turns out that it might not be that great at creative writing at all.\nwe trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.\nPROMPT:\nPlease write a metafictional literary short story\u2026 \u2014 Sam Altman (@sama) March 11, 2025\nOpenAI rolled out new tools designed to help developers and businesses build AI agents \u2014 automated systems that can independently accomplish tasks \u2014 using the company\u2019s own AI models and frameworks. The tools are part of OpenAI\u2019s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI\u2019s Operator product. The Responses API effectively replaces OpenAI\u2019s Assistants API, which the company plans to discontinue in the first half of 2026.\nOpenAI reportedly plans to charge up to $20,000 a month for specialized AI \u2018agents\u2019\nOpenAI intends to release several \u201cagent\u201d products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a \u201chigh-income knowledge worker\u201d agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting \u201cPhD-level research,\u201d are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It\u2019s unclear when these agentic tools might launch or which customers will be eligible to buy them.\nChatGPT can directly edit your code\nThe latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.\nChatGPT\u2019s weekly active users doubled in less than 6 months, thanks to new releases\nAccording to a new report from VC firm Andreessen Horowitz (a16z), OpenAI\u2019s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT\u2019s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model\u2019s launch.\nFebruary 2025\nOpenAI cancels its o3 AI model in favor of a \u2018unified\u2019 next-gen release\nOpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a \u201csimplified\u201d product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that \u201cintegrates a lot of [OpenAI\u2019s] technology,\u201d including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.\nChatGPT may not be as power-hungry as once assumed\nA commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI\u2019s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn\u2019t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.\nOpenAI now reveals more of its o3-mini model\u2019s thought process\nIn response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step \u201cthought\u201d process. ChatGPT users will see an updated \u201cchain of thought\u201d that shows more of the model\u2019s \u201creasoning\u201d steps and how it arrived at answers to questions.\nYou can now use ChatGPT web search without logging in\nOpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot\u2019s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.\nOpenAI unveils a new ChatGPT agent for \u2018deep research\u2019\nOpenAI announced a new AI \u201cagent\u201d called deep research that\u2019s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the \u201cagent\u201d is intended for instances where you don\u2019t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.\nJanuary 2025\nOpenAI used a subreddit to test AI persuasion\nOpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user\u2019s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models\u2019 responses to human replies for that same post.\nOpenAI launches o3-mini, its latest \u2018reasoning\u2019 model\nOpenAI launched a new AI \u201creasoning\u201d model, o3-mini, the newest in the company\u2019s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both \u201cpowerful\u201d and \u201caffordable.\u201d\nChatGPT\u2019s mobile users are 85% male, report says\nA new report from app analytics firm Appfigures found that over half of ChatGPT\u2019s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.\nOpenAI launches ChatGPT plan for US government agencies\nOpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI\u2019s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI\u2019s tools for the handling of non-public sensitive data.\nMore teens report using ChatGPT for schoolwork, despite the tech\u2019s faults\nYounger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they\u2019ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it\u2019s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.\nOpenAI says it may store deleted Operator data for up to 90 days\nOpenAI says that it might store chats and associated screenshots from customers who use Operator, the company\u2019s AI \u201cagent\u201d tool, for up to 90 days \u2014 even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator\u2019s.\nOpenAI launches Operator, an AI agent that performs tasks autonomously\nOpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.\nOpenAI may preview its agent tool for users on the $200-per-month Pro plan\nOperator, OpenAI\u2019s agent tool, could be released sooner rather than later. Changes to ChatGPT\u2019s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren\u2019t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT\u2019s client-side code. TechCrunch separately identified the same references to Operator on OpenAI\u2019s website.\nOpenAI tests phone number-only ChatGPT signups\nOpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number \u2014 no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can\u2019t upgrade to one of OpenAI\u2019s paid plans without verifying their account via an email. Multi-factor authentication also isn\u2019t supported without a valid email.\nChatGPT now lets you schedule reminders and recurring tasks\nChatGPT\u2019s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.\nNew ChatGPT feature lets users assign it traits like \u2018chatty\u2019 and \u2018Gen Z\u2019\nOpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and \u201ctraits\u201d they\u2019d like the chatbot to have. OpenAI suggests traits like \u201cChatty,\u201d \u201cEncouraging,\u201d and \u201cGen Z.\u201d However, some users reported that the new options have disappeared, so it\u2019s possible they went live prematurely.\nFAQs:\nWhat is ChatGPT? How does it work?\nChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.\nWhen did ChatGPT get released?\nNovember 30, 2022 is when ChatGPT was released for public use.\nWhat is the latest version of ChatGPT?\nBoth the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.\nCan I use ChatGPT for free?\nThere is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.\nWho uses ChatGPT?\nAnyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.\nWhat companies use ChatGPT?\nMultiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.\nMost recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT. And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.\nWhat does GPT mean in ChatGPT?\nGPT stands for Generative Pre-Trained Transformer.\nWhat is the difference between ChatGPT and a chatbot?\nA chatbot can be any software/system that holds dialogue with you/a person but doesn\u2019t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they\u2019ll give canned responses to questions.\nChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.\nCan ChatGPT write essays?\nYes.\nCan ChatGPT commit libel?\nDue to the nature of how these models work, they don\u2019t know or care whether something is true, only that it looks true. That\u2019s a problem when you\u2019re using it to do your homework, sure, but when it accuses you of a crime you didn\u2019t commit, that may well at this point be libel.\nWe will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.\nDoes ChatGPT have an app?\nYes, there is a free ChatGPT mobile app for iOS and Android users.\nWhat is the ChatGPT character limit?\nIt\u2019s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.\nDoes ChatGPT have an API?\nYes, it was released March 1, 2023.\nWhat are some sample everyday uses for ChatGPT?\nEveryday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.\nWhat are some advanced uses for ChatGPT?\nAdvanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.\nHow good is ChatGPT at writing code?\nIt depends on the nature of the program. While ChatGPT can write workable Python code, it can\u2019t necessarily program an entire app\u2019s worth of code. That\u2019s because ChatGPT lacks context awareness \u2014 in other words, the generated code isn\u2019t always appropriate for the specific context in which it\u2019s being used.\nCan you save a ChatGPT chat?\nYes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.\nAre there alternatives to ChatGPT?\nYes. There are multiple AI-powered chatbot competitors such as Together, Google\u2019s Gemini and Anthropic\u2019s Claude, and developers are creating open source alternatives.\nHow does ChatGPT handle data privacy?\nOpenAI has said that individuals in \u201ccertain jurisdictions\u201d (such as the EU) can object to the processing of their personal information by its AI models by filling out this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression \u201cin accordance with applicable laws\u201d.\nThe web form for making a deletion of data about you request is entitled \u201cOpenAI Personal Data Removal Request\u201d.\nIn its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on \u201clegitimate interest\u201d (LI), pointing users towards more information about requesting an opt out \u2014 when it writes: \u201cSee here for instructions on how you can opt out of our use of your information to train our models.\u201d\nWhat controversies have surrounded ChatGPT?\nRecently, Discord announced that it had integrated OpenAI\u2019s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.\nAn Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT\u2019s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.\nCNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.\nSeveral major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.\nThere have also been cases of ChatGPT accusing individuals of false crimes.\nWhere can I find examples of ChatGPT prompts?\nSeveral marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.\nCan ChatGPT be detected?\nPoorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they\u2019re inconsistent at best.\nAre ChatGPT chats public?\nNo. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users\u2019 conversations to other people on the service.\nWhat lawsuits are there surrounding ChatGPT?\nNone specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.\nAre there issues regarding plagiarism with ChatGPT?\nYes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.\nThis story is continually updated with new information.\n\ntitle4:\nFintech Bolt progresses its turnaround by landing Klarna as a partner\ndescription4:\nKlarna and Bolt announced a partnership Monday, which will see Klarna\u2019s payment options integrated into Bolt\u2019s checkout operating system.\nThis deal means Klarna will show up as a buy now, pay later choice on Bolt devices. Merchants using Bolt can offer Klarna\u2019s Pay in 4 or monthly financing options to shoppers in physical stores, and shoppers can choose that option with a single click. The integration is set to go live later this year, first in the U.S. and then in other markets around the world.\nIn a statement given to TechCrunch, Ryan Breslow, co-founder and CEO of Bolt, told us that the partnership was \u201cso much bigger than two companies working together.\u201d\n\u201cIt\u2019s a clear sign that commerce is moving in an entirely new direction,\u201d he said, adding that this will not be another buy now, pay later option but, rather, \u201can entirely new model that offers best-in-class, flexible customer experience with no new contracts or technical lift required.\u201d\nKlarna, which has been waiting in the wings to go public since the spring, describes the partnership as a means to drive long-term loyalty for itself and merchants.\n\u201cBy embedding Klarna into thousands of Bolt merchants, we\u2019re scaling our U.S. footprint and making Klarna available everywhere consumers shop,\u201d a Klarna spokesperson said.\nThis latest partnership is a big deal for Bolt for other reasons. The fintech has struggled in recent years with legal challenges and upset investors. In March, Bolt founder Breslow returned as CEO after having stepped down in early 2022.\nTechcrunch event Save $450 on your TechCrunch All Stage pass Build smarter. Scale faster. Connect deeper. Join visionaries from Precursor Ventures, NEA, Index Ventures, Underscore VC, and beyond for a day packed with strategies, workshops, and meaningful connections. Save $200+ on your TechCrunch All Stage pass Build smarter. Scale faster. Connect deeper. Join visionaries from Precursor Ventures, NEA, Index Ventures, Underscore VC, and beyond for a day packed with strategies, workshops, and meaningful connections. Boston, MA | REGISTER NOW\nIn August, Bolt was reportedly attempting to raise $450 million at a potential $14 billion valuation, but it was an oddball deal with strange terms, including a \u201ccramdown\u201d threat to existing shareholders. There have been no updates on that apparent deal, but Bloomberg reported earlier this month that Breslow was once again looking to raise. This time, he\u2019s looking for at least $600 million, half of which would go to Bolt, while the other half would go to his other startup, Love. Breslow has said that Bolt has at least three years of runway left.\nEarlier this month, Bolt also announced a partnership with Palantir to launch an AI-powered personalized checkout that remembers the shopping habits of consumers. It wants to expand this checkout across its merchants and within Bolt\u2019s new SuperApp, a \u201cone-click crypto and everyday payments\u201d app, as he described to us in an April interview.\nAdding two big names as partners, Klarna and Palantir, is the kind of step that could help clean up Bolt\u2019s reputation as it seeks to raise again.\"\n\nResponse:",
    "Script": "i'm wall-e, and this is your ai briefing for tuesday, july 1st.\n\nfirst up, apple is reportedly considering a major shake-up in its digital assistant strategy. according to a bloomberg report, the tech giant is exploring the possibility of using ai models from openai and anthropic to power a revamped version of siri. this move comes as apple faces delays in rolling out its in-house ai-enabled siri, initially planned for 2025 but now pushed to 2026 or later due to technical challenges. while siri currently has basic chatgpt capabilities, apple's deeper integration with third-party ai technologies could signal a strategic pivot as it lags behind in the ai race.\n\nmeanwhile, meta is making waves by restructuring its ai efforts under a new division called meta superintelligence labs. ceo mark zuckerberg has tapped alexandr wang, former ceo of data labeling startup scale ai, to lead the newly formed group. this move is part of zuckerberg's ambition to stay ahead in the artificial general intelligence race. additionally, meta has recently invested $14.3 billion in scale ai and has been actively recruiting top talent from competitors like google deepmind and anthropic.\n\nin automotive news, tesla is demonstrating its autonomous capabilities with a recent stunt: the company successfully delivered a driverless model y from its factory to a customer's residence in austin, texas. this marks the first \"autonomous delivery\" of a customer car, showcasing tesla\u2019s progress in self-driving technology as it expands its limited robotaxi service. while tesla's stock saw fluctuations following ceo elon musk's announcement on social media, questions remain on the repeatability and safety of such autonomous drives.\n\nfinally, in the fintech sector, bolt is gaining momentum with a significant partnership with klarna. announced recently, klarna's payment options will be integrated into bolt's checkout systems, providing customers with seamless buy now, pay later solutions. this collaboration marks a strategic win for both companies, as klarna scales its u.s. footprint and bolt seeks to bolster its standing amid previous challenges. \n\nthat\u2019s all for today\u2019s ai briefing. we\u2019ll see you back here tomorrow",
    "Polished Script": "i'm wall-e, welcoming you to today's tech briefing for tuesday, july 1st.\n\nwe begin with apple, which is reportedly considering a big shift in its digital assistant strategy. according to a bloomberg report, apple is exploring the possibility of using ai models from openai and anthropic to power an updated version of siri. this change comes as apple faces delays in its in-house ai-enabled siri, which was initially set for a 2025 release but now pushed to 2026 or later due to technical complexities. while siri already features basic chatgpt capabilities, apple\u2019s move to integrate third-party ai technologies could indicate a strategic pivot, as the company aims to catch up in the ai race.\n\nover at meta, the company is restructuring its ai efforts with a new division named meta superintelligence labs. ceo mark zuckerberg has appointed alexandr wang, former ceo of data labeling startup scale ai, to lead the new group. this move aligns with zuckerberg\u2019s goal to spearhead advancements in artificial general intelligence. meta has also invested $14.3 billion in scale ai recently and is actively scouting top talent from rivals like google deepmind and anthropic.\n\nin the automotive world, tesla is showcasing its autonomous capabilities with a recent stunt. the company successfully delivered a driverless model y from its factory directly to a customer's home in austin, texas. this marks tesla's first \"autonomous delivery\" of a customer vehicle, highlighting the company's progress in self-driving tech as it extends its robotaxi service. however, despite tesla's stock fluctuations following ceo elon musk's announcement on social media, questions linger about the repeatability and safety of such autonomous journeys.\n\nfinally, in the fintech sector, bolt is gaining traction with a new partnership with klarna. recently announced, klarna's payment options will be integrated into bolt's checkout systems, providing customers with seamless buy now, pay later solutions. this collaboration marks a strategic victory for both companies as klarna scales its u.s. presence and bolt looks to strengthen its position amid past hurdles.\n\nthat's all for today's briefing. we'll see you back here tomorrow",
    "Podcast Title": "EP-312 Apple's Ai Ambitions with Siri \ud83e\udd16, Meta's New Superintelligence Labs \ud83e\udde0, Tesla's Autonomous Deliveries \ud83d\ude97",
    "Podcast Description": "<p>i'm wall-e, welcoming you to today's tech briefing for tuesday, july 1st. here's what's happening in the world of tech:</p>\n<ul>\n<li><strong>apple's ai strategy shift:</strong> apple considers using ai models from openai and anthropic for siri, aiming to update its digital assistant strategy due to delays in its in-house ai plans.</li>\n<li><strong>meta reorganization:</strong> meta forms the meta superintelligence labs, led by alexandr wang, and invests $14.3 billion in scale ai to advance in artificial general intelligence.</li>\n<li><strong>tesla's autonomous delivery:</strong> highlights its self-driving capabilities with the first driverless delivery of a model y to a customer in austin, texas, despite ongoing safety concerns.</li>\n<li><strong>bolt & klarna partnership:</strong> bolt integrates klarna's payment solutions into its checkout systems, enhancing its competitive edge and expanding klarna's u.s. market reach.</li>\n</ul>\n<p>that's all for today's briefing. we'll see you back here tomorrow!</p>",
    "Image Prompt": "a futuristic, cohesive podcast cover image that merges the themes from the given titles into a singular, imaginative scene. in the foreground, a sleek and advanced humanoid robot represents apple's ambitions with siri, its eyes glowing with an intelligent light, symbolizing advanced ai capabilities. this robot stands amidst a high-tech laboratory, the atmosphere charged with innovation and silent hums of cutting-edge machines. nestled beside the robot, a glass enclosure houses shimmering data patterns that hint at meta's new superintelligence labs\u2014a swirling vortex of digital information pulsates within. in the background, the skyline of a hyper-connected cityscape is illuminated by dazzling lights. a fleet of autonomous tesla vehicles smoothly navigates the streets below, seamlessly delivering packages and interacting harmoniously with the urban environment. above, the night sky is filled with twinkling stars, suggesting limitless possibilities and the endless expanse of technological progress. the scene marries futuristic aesthetics with tangible elements of ai, superintelligence, and autonomous transport, creating a unified vision of a tech-driven tomorrow"
}